{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a53c17-095b-40e8-b51a-4555ae91cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated installation command for latest CPU-compatible PyTorch\n",
    "!pip install torch==2.2.2+cpu torchvision==0.17.2+cpu torchaudio==2.2.2+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c1519-7ba8-4aee-9f5d-04641ad0ca18",
   "metadata": {},
   "source": [
    "# Cyber Threat Forecasting Using TCN + ARIMA Hybrid Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba07120-6e44-4f1a-8b4e-748061bc2566",
   "metadata": {},
   "source": [
    "## By analyzing patterns in real-world cyberattack data, the model aims to predict future incident counts and help organizations prepare proactively. The project also includes thorough EDA, visualizations, and per-industry insights, making it suitable for both operational intelligence and academic demonstration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eab7ad-4e01-4def-936b-34533ca595d6",
   "metadata": {},
   "source": [
    "### Installing required libraries and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e30f8-27a5-49cf-8faf-22e046804555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "data = pd.read_csv(\"Incidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ffbfc-483f-4ade-b604-543ed84ef0a4",
   "metadata": {},
   "source": [
    "### EDA and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdcd7d-9d18-4169-a187-909436497211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "data.dropna(subset=['Date'], inplace=True)\n",
    "data['YearMonth'] = data['Date'].dt.to_period('M')\n",
    "data['Sub-Type'] = data['Sub-Type'].fillna(\"Unknown\")\n",
    "\n",
    "\n",
    "grouped_data = data.groupby('YearMonth').agg({\n",
    "    'Type': lambda x: Counter(x).most_common(1)[0][0],\n",
    "    'Sub-Type': lambda x: Counter(x).most_common(1)[0][0],\n",
    "    'Date': 'count'\n",
    "}).reset_index().rename(columns={'Date': 'Incident count'})\n",
    "\n",
    "\n",
    "grouped_data['YearMonth_encoded'] = pd.to_datetime(grouped_data['YearMonth'].astype(str)).view('int64') / 1e9\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "grouped_data['Incident count_scaled'] = scaler.fit_transform(grouped_data[['Incident count']])\n",
    "\n",
    "# Lag features\n",
    "grouped_data['Lag_1'] = grouped_data['Incident count_scaled'].shift(1).fillna(0)\n",
    "grouped_data['Lag_2'] = grouped_data['Incident count_scaled'].shift(2).fillna(0)\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(f\"\\n Date Range: {data['Date'].min()} to {data['Date'].max()}\")\n",
    "\n",
    "print(f\"Unique Industries: {data['Industry'].nunique()}\")\n",
    "print(f\"Unique Types: {data['Type'].nunique()}\")\n",
    "print(f\"Unique Sub-Types: {data['Sub-Type'].nunique()}\")\n",
    "print(f\"Unique Locations: {data['Location'].nunique()}\")\n",
    "\n",
    "# Top categories\n",
    "for col in ['Industry', 'Type', 'Sub-Type', 'Location']:\n",
    "    print(f\"\\nTop 5 in '{col}':\")\n",
    "    print(data[col].value_counts().head())\n",
    "\n",
    "# Monthly distribution\n",
    "data['YearMonth'] = data['Date'].dt.to_period('M')\n",
    "monthly_counts = data.groupby('YearMonth').size()\n",
    "print(\"\\nMonthly Incident Count Stats:\")\n",
    "print(monthly_counts.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4823e-75e4-4542-9bf8-8e5d4d3cd885",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960aa275-3f60-4cae-970a-7b4ad0442ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "#Monthly incident count \n",
    "monthly_counts = data.resample('M', on='Date').size()\n",
    "plt.plot(monthly_counts.index, monthly_counts.values, marker='o', color='teal')\n",
    "plt.title(\"Monthly Incident Counts\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Incident Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#Top 5 attack types\n",
    "attack_counts = data['Type'].value_counts().head(5)\n",
    "sns.barplot(x=attack_counts.values, y=attack_counts.index, palette='muted')\n",
    "plt.title(\"Top 5 Attack Types\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "#Top 10 industries\n",
    "industry_counts = data['Industry'].value_counts().head(10)\n",
    "sns.barplot(x=industry_counts.values, y=industry_counts.index, palette='coolwarm')\n",
    "plt.title(\"Top 10 Affected Industries\")\n",
    "plt.xlabel(\"Incident Count\")\n",
    "plt.show()\n",
    "\n",
    "#Top 10 countries\n",
    "location_counts = data['Location'].value_counts().head(10)\n",
    "sns.barplot(x=location_counts.values, y=location_counts.index, palette='viridis')\n",
    "plt.title(\"Top 10 Countries Affected\")\n",
    "plt.xlabel(\"Incident Count\")\n",
    "plt.show()\n",
    "\n",
    "#Heatmap of Attack Type vs Industry\n",
    "pivot = data.pivot_table(index='Industry', columns='Type', aggfunc='size', fill_value=0)\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(pivot, cmap='YlGnBu', linewidths=0.5)\n",
    "plt.title(\"Heatmap: Attack Type vs Industry\")\n",
    "plt.xlabel(\"Attack Type\")\n",
    "plt.ylabel(\"Industry\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#most common attack type\n",
    "top_attack_type = data['Type'].value_counts().idxmax()\n",
    "monthly_top_attack = data[data['Type'] == top_attack_type].resample('M', on='Date').size()\n",
    "plt.plot(monthly_top_attack.index, monthly_top_attack.values, marker='o', color='crimson')\n",
    "plt.title(f\"Trend of '{top_attack_type}' Incidents Over Time\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Incident Count\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34d4ca-44d8-4ae2-a09a-b2219e443f3a",
   "metadata": {},
   "source": [
    "### Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e68be-0113-4f30-9136-003754749d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IQR method to detect and cap outliers in 'Incident count'\n",
    "Q1 = grouped_data['Incident count'].quantile(0.25)\n",
    "Q3 = grouped_data['Incident count'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Capping the values instead of removing to preserve continuity\n",
    "grouped_data['Incident count'] = np.where(grouped_data['Incident count'] < lower_bound, lower_bound,\n",
    "                                          np.where(grouped_data['Incident count'] > upper_bound, upper_bound,\n",
    "                                                   grouped_data['Incident count']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604aa8e-0594-4adc-bf24-4fb0fdb124f6",
   "metadata": {},
   "source": [
    "### Training TCN + ARIMA Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc8642-763f-4072-9c41-c570a66e5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=(kernel_size - 1) * dilation, dilation=dilation)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.dropout1)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "        return out[:, :, :-out.size(2) + x.size(2)] + x\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.tcn = nn.Sequential(\n",
    "            TemporalBlock(input_size, 64, kernel_size=2, dilation=1),\n",
    "            TemporalBlock(64, 32, kernel_size=2, dilation=2),\n",
    "        )\n",
    "        self.linear = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)\n",
    "        return self.linear(y1[:, :, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629189fd-70f5-4f0c-89d9-583643df895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "features = grouped_data[['Lag_1', 'Lag_2']].values\n",
    "labels = grouped_data['Incident count_scaled'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Model\n",
    "model = TCN(input_size=1, output_size=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor).squeeze()\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/200, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627fdeb-9073-48bb-bb4b-7eaec48a345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCN Prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_tcn = model(X_test_tensor).squeeze().numpy()\n",
    "\n",
    "# Inverse scale\n",
    "tcn_pred_rescaled = scaler.inverse_transform(pred_tcn.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ARIMA on residuals\n",
    "residuals = y_train - model(X_train_tensor).squeeze().detach().numpy()\n",
    "arima_model = auto_arima(residuals, seasonal=False, trace=False)\n",
    "arima_forecast = arima_model.predict(n_periods=len(y_test))\n",
    "\n",
    "# Hybrid Forecast = TCN + ARIMA\n",
    "hybrid_forecast = tcn_pred_rescaled + arima_forecast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe0023-54d1-4a18-9d59-6f46e4b07447",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5fa965-8638-45d1-a64d-e874e2818aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "actual_values = grouped_data['Incident count'][-len(y_test):].values\n",
    "mae = mean_absolute_error(actual_values, hybrid_forecast)\n",
    "mse = mean_squared_error(actual_values, hybrid_forecast)\n",
    "mape = mean_absolute_percentage_error(actual_values, hybrid_forecast)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"MAPE: {mape * 100:.2f}%\")\n",
    "print(f\"Accuracy: {100 - mape * 100:.2f}%\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(grouped_data['YearMonth'][-len(y_test):].astype(str), actual_values, label='Actual', marker='o')\n",
    "plt.plot(grouped_data['YearMonth'][-len(y_test):].astype(str), hybrid_forecast, label='Hybrid Forecast', linestyle='--', marker='x')\n",
    "plt.title(\"TCN + ARIMA Forecast vs Actual\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Incident Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Table\n",
    "pd.DataFrame({\n",
    "    'YearMonth': grouped_data['YearMonth'][-len(y_test):].astype(str),\n",
    "    'Actual': actual_values,\n",
    "    'Forecast (TCN + ARIMA)': np.round(hybrid_forecast).astype(int)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be8f9cb-009b-4739-82ab-49250965e386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
